{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289},{"sourceId":8399585,"sourceType":"datasetVersion","datasetId":4997444},{"sourceId":8451238,"sourceType":"datasetVersion","datasetId":5011573},{"sourceId":8464051,"sourceType":"datasetVersion","datasetId":5045888}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image-captioning-with-Attention","metadata":{}},{"cell_type":"code","source":"#imports \nimport os\nimport numpy as np\nfrom collections import Counter\nimport spacy\nimport pandas as pd\nfrom PIL import Image\nimport typing\nfrom typing import List\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader,Dataset\nfrom torch import optim\nfrom torch.nn import functional\nfrom torchvision import transforms\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:55:57.367064Z","iopub.execute_input":"2024-05-21T04:55:57.367816Z","iopub.status.idle":"2024-05-21T04:56:07.140137Z","shell.execute_reply.started":"2024-05-21T04:55:57.367785Z","shell.execute_reply":"2024-05-21T04:56:07.139184Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"code","source":"data_location =  \"../input/flickr8k\"","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:19.095289Z","iopub.execute_input":"2024-05-21T04:56:19.095866Z","iopub.status.idle":"2024-05-21T04:56:19.100281Z","shell.execute_reply.started":"2024-05-21T04:56:19.095832Z","shell.execute_reply":"2024-05-21T04:56:19.099388Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#reading the text data \nimport pandas as pd\ncaptions_file = data_location + '/captions.txt'\ncaptions_df = pd.read_csv(captions_file)\nprint(f\"There are {len(captions_df)} image to captions\")\ncaptions_df.head(7)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:21.130798Z","iopub.execute_input":"2024-05-21T04:56:21.131167Z","iopub.status.idle":"2024-05-21T04:56:21.242370Z","shell.execute_reply.started":"2024-05-21T04:56:21.131138Z","shell.execute_reply":"2024-05-21T04:56:21.241351Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"There are 40455 image to captions\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                       image  \\\n0  1000268201_693b08cb0e.jpg   \n1  1000268201_693b08cb0e.jpg   \n2  1000268201_693b08cb0e.jpg   \n3  1000268201_693b08cb0e.jpg   \n4  1000268201_693b08cb0e.jpg   \n5  1001773457_577c3a7d70.jpg   \n6  1001773457_577c3a7d70.jpg   \n\n                                             caption  \n0  A child in a pink dress is climbing up a set o...  \n1              A girl going into a wooden building .  \n2   A little girl climbing into a wooden playhouse .  \n3  A little girl climbing the stairs to her playh...  \n4  A little girl in a pink dress going into a woo...  \n5         A black dog and a spotted dog are fighting  \n6  A black dog and a tri-colored dog playing with...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing the stairs to her playh...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl in a pink dress going into a woo...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1001773457_577c3a7d70.jpg</td>\n      <td>A black dog and a spotted dog are fighting</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1001773457_577c3a7d70.jpg</td>\n      <td>A black dog and a tri-colored dog playing with...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# First, let's get unique image IDs\nunique_image_ids = captions_df['image'].unique()\n\n# Sort the unique image IDs\nsorted_image_ids = sorted(unique_image_ids)\n\n# Calculate the index to split the data\nsplit_index = int(len(sorted_image_ids) * 0.8)  # 80-20 split\n\n# Split the sorted image IDs into train and test sets\ntrain_image_ids = sorted_image_ids[:split_index]\ntest_image_ids = sorted_image_ids[split_index:]\n\n# Now filter the DataFrame based on train and test image IDs\ntrain_df = captions_df[captions_df['image'].isin(train_image_ids)]\ntest_df = captions_df[captions_df['image'].isin(test_image_ids)]\n\n# Ensure no image is in both train and test sets\nassert len(set(train_df['image'].unique()).intersection(set(test_df['image'].unique()))) == 0\n\n# Now train_df and test_df contain the split data\n# captions_df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:22.557131Z","iopub.execute_input":"2024-05-21T04:56:22.557763Z","iopub.status.idle":"2024-05-21T04:56:22.586377Z","shell.execute_reply.started":"2024-05-21T04:56:22.557729Z","shell.execute_reply":"2024-05-21T04:56:22.585486Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Building Vocabulary","metadata":{}},{"cell_type":"code","source":"class Vocabulary:\n    #using spacy for text tokenization \n    spacy_eng = spacy.load(\"en_core_web_sm\")\n\n    def __init__(self,freq_threshold):\n        #setting the pre-reserved tokens int to string tokens\n        self.index_to_str = {0:\"<PAD>\",1:\"<SOS>\",2:\"<EOS>\",3:\"<UNK>\"}\n        \n        #string to int tokens\n        self.str_to_index = {v:k for k,v in self.index_to_str.items()}\n        \n        #threshold for unkown words\n        self.freq_threshold = freq_threshold\n        \n    def __len__(self): \n        return len(self.index_to_str)\n    \n    def build_vocab(self, sentence_list:List):\n        tocken_frequencies = Counter()\n        tocken_index = 4 # because 0->3 are already defined\n        \n        for sentence in sentence_list:\n            for word in self.tokenize(sentence):\n                tocken_frequencies[word] += 1\n                \n                #add the word to the vocab if it reaches minum frequecy threshold\n                if tocken_frequencies[word] == self.freq_threshold:\n                    self.str_to_index[word] = tocken_index\n                    self.index_to_str[tocken_index] = word\n                    tocken_index += 1\n    \n    def sentence_to_indices(self,text):\n        \"\"\" For each word in the text corresponding index token for that word form the vocab built as list \"\"\"\n        tokenized_text = self.tokenize(text)\n        return [ self.str_to_index[token] if token in self.str_to_index else self.str_to_index[\"<UNK>\"] for token in tokenized_text ]  \n    \n    def indices_to_sentence(indices, index_to_str):\n        \"\"\" Convert a list of indices back to a sentence using a provided index_to_str mapping \"\"\"\n        return ' '.join([index_to_str[index] for index in indices])\n    \n    @staticmethod\n    def tokenize(text):\n        return [token.text.lower() for token in Vocabulary.spacy_eng.tokenizer(text)]","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:24.367713Z","iopub.execute_input":"2024-05-21T04:56:24.368579Z","iopub.status.idle":"2024-05-21T04:56:25.822797Z","shell.execute_reply.started":"2024-05-21T04:56:24.368544Z","shell.execute_reply":"2024-05-21T04:56:25.821785Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#testing the vicab class \nv = Vocabulary(freq_threshold=1)\n\nv.build_vocab([\"This is a good place to find a city\"])\nprint(v.str_to_index)\nprint(v.sentence_to_indices(\"This is a good place to find a city here!!\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:25.824518Z","iopub.execute_input":"2024-05-21T04:56:25.824816Z","iopub.status.idle":"2024-05-21T04:56:25.831206Z","shell.execute_reply.started":"2024-05-21T04:56:25.824792Z","shell.execute_reply":"2024-05-21T04:56:25.830160Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'this': 4, 'is': 5, 'a': 6, 'good': 7, 'place': 8, 'to': 9, 'find': 10, 'city': 11}\n[4, 5, 6, 7, 8, 9, 10, 6, 11, 3, 3, 3]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building Dataset","metadata":{}},{"cell_type":"code","source":"class FlickrDataset(Dataset):\n    \"\"\"\n    FlickrDataset object for easy manipulation\n    \"\"\"\n    def __init__(self,images_dir,captions_df,transform=None,freq_threshold=5):\n        self.images_dir = images_dir #root directory of flickr that contains the images folder\n        self.captions_df = captions_df\n        self.transform = transform\n        \n        #Get image and caption colum from the dataframe\n        self.imgs = self.captions_df[\"image\"]\n        self.captions = self.captions_df[\"caption\"]\n        \n        #Initialize vocabulary and build vocab\n        self.vocab = Vocabulary(freq_threshold)\n        self.vocab.build_vocab(self.captions.tolist())\n        \n    \n    def __len__(self):\n        return len(self.captions_df)\n    \n    def __getitem__(self,index):\n        caption = self.captions[index]\n        img_name = self.imgs[index]\n        img_location = os.path.join(self.images_dir,img_name)\n        img = Image.open(img_location).convert(\"RGB\")\n        \n        #apply the transfromation to the image\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        #sentence_to_indices the caption text\n        caption_vec = []\n        caption_vec += [self.vocab.str_to_index[\"<SOS>\"]]\n        caption_vec += self.vocab.sentence_to_indices(caption)\n        caption_vec += [self.vocab.str_to_index[\"<EOS>\"]]\n        \n        return img, torch.tensor(caption_vec)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:26.458091Z","iopub.execute_input":"2024-05-21T04:56:26.458450Z","iopub.status.idle":"2024-05-21T04:56:26.467915Z","shell.execute_reply.started":"2024-05-21T04:56:26.458423Z","shell.execute_reply":"2024-05-21T04:56:26.466896Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Image_Captions_Collate:\n    \"\"\"\n    Collate to apply the padding to the captions with dataloader\n    \"\"\"\n    def __init__(self,padding_tocken_idx,batch_first=False):\n        self.padding_tocken_idx = padding_tocken_idx\n        self.batch_first = batch_first\n    \n    def __call__(self,batch):\n        imgs = [item[0].unsqueeze(0) for item in batch]\n        imgs = torch.cat(imgs,dim=0)\n        \n        targets = [item[1] for item in batch]\n        targets = pad_sequence(targets, batch_first=self.batch_first, padding_value=self.padding_tocken_idx)\n        return imgs,targets","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:27.573156Z","iopub.execute_input":"2024-05-21T04:56:27.573816Z","iopub.status.idle":"2024-05-21T04:56:27.580326Z","shell.execute_reply.started":"2024-05-21T04:56:27.573780Z","shell.execute_reply":"2024-05-21T04:56:27.579368Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#setting the constants\ndata_location =  \"../input/flickr8k\"\n\n\n#defining the transform to be applied\nimages_transforms = transforms.Compose([\n    transforms.Resize(226),                     \n    transforms.RandomCrop(224),                 \n    transforms.ToTensor(),                               \n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n])\n\n\n#testing the dataset class\ntrain_dataset =  FlickrDataset(\n    images_dir = data_location+\"/Images\",\n    captions_df = train_df,\n    transform = images_transforms\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:28.425267Z","iopub.execute_input":"2024-05-21T04:56:28.425648Z","iopub.status.idle":"2024-05-21T04:56:30.266174Z","shell.execute_reply.started":"2024-05-21T04:56:28.425618Z","shell.execute_reply":"2024-05-21T04:56:30.265177Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-20T21:45:59.144074Z","iopub.execute_input":"2024-05-20T21:45:59.144352Z","iopub.status.idle":"2024-05-20T21:45:59.150071Z","shell.execute_reply.started":"2024-05-20T21:45:59.144329Z","shell.execute_reply":"2024-05-20T21:45:59.149218Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<__main__.FlickrDataset at 0x7e36934e4b80>"},"metadata":{}}]},{"cell_type":"code","source":"import dill as pickle\nwith open(\"/kaggle/working/train_dataset.pkl\",\"wb\")as f:\n    pickle.dump(train_dataset,f)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T03:44:19.894191Z","iopub.execute_input":"2024-05-21T03:44:19.894592Z","iopub.status.idle":"2024-05-21T03:44:22.424223Z","shell.execute_reply.started":"2024-05-21T03:44:19.894560Z","shell.execute_reply":"2024-05-21T03:44:22.423050Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pad_idx = train_dataset.vocab.str_to_index[\"<PAD>\"]\n\n#setting the constants\nBATCH_SIZE = 256\nNUM_WORKER = 4\n\n#writing the dataloader\ndata_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=NUM_WORKER,\n    shuffle=True,\n    # batch_first=False\n    collate_fn=Image_Captions_Collate(padding_tocken_idx=pad_idx,batch_first=True)\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:31.211164Z","iopub.execute_input":"2024-05-21T04:56:31.211530Z","iopub.status.idle":"2024-05-21T04:56:31.217575Z","shell.execute_reply.started":"2024-05-21T04:56:31.211499Z","shell.execute_reply":"2024-05-21T04:56:31.216578Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Encoder","metadata":{}},{"cell_type":"code","source":"class EncoderCNN(nn.Module):\n    def __init__(self):\n        super(EncoderCNN, self).__init__()\n        resnet = models.resnet50(pretrained=True)\n        for param in resnet.parameters():\n            param.requires_grad_(False)\n        \n        modules = list(resnet.children())[:-2]\n        self.resnet = nn.Sequential(*modules)\n        \n\n    def forward(self, images):\n        features = self.resnet(images)                                    #(batch_size,2048,7,7)\n        features = features.permute(0, 2, 3, 1)                           #(batch_size,7,7,2048)\n        features = features.view(features.size(0), -1, features.size(-1)) #(batch_size,49,2048)\n        return features\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:30:31.615114Z","iopub.execute_input":"2024-05-21T05:30:31.615497Z","iopub.status.idle":"2024-05-21T05:30:31.623241Z","shell.execute_reply.started":"2024-05-21T05:30:31.615461Z","shell.execute_reply":"2024-05-21T05:30:31.622255Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Attention","metadata":{}},{"cell_type":"code","source":"#Bahdanau Attention\nclass Attention(nn.Module):\n    def __init__(self, encoder_dim,decoder_dim,attention_dim):\n        super(Attention, self).__init__()\n        \n        self.attention_dim = attention_dim\n        \n        self.decoder_attention = nn.Linear(decoder_dim,attention_dim)\n        self.encoder_attention = nn.Linear(encoder_dim,attention_dim)\n        self.cell_attention = nn.Linear(decoder_dim, attention_dim)\n\n        self.attention_layer = nn.Linear(attention_dim,1)\n        \n    def forward(self, features, hidden_state, cell_state):\n        encoder_attention_states = self.encoder_attention(features)     #(batch_size,num_layers,attention_dim)\n        decoder_attention_states = self.decoder_attention(hidden_state) #(batch_size,attention_dim)\n        cell_attention_states = self.cell_attention(cell_state)         #(batch_size, attention_dim)\n\n        combined_states = torch.tanh(encoder_attention_states + decoder_attention_states.unsqueeze(1) + cell_attention_states.unsqueeze(1)) #(batch_size,num_layers,attemtion_dim)\n        \n        attention_scores = self.attention_layer(combined_states)         #(batch_size,num_layers,1)\n        attention_scores = attention_scores.squeeze(2)     #(batch_size,num_layers)\n        \n        \n        alpha = functional.softmax(attention_scores,dim=1)          #(batch_size,num_layers)\n        \n        attention_weights = features * alpha.unsqueeze(2)  #(batch_size,num_layers,features_dim)\n        attention_weights = attention_weights.sum(dim=1)   #(batch_size,num_layers)\n        \n        return alpha,attention_weights\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:30:48.795390Z","iopub.execute_input":"2024-05-21T05:30:48.795768Z","iopub.status.idle":"2024-05-21T05:30:48.805191Z","shell.execute_reply.started":"2024-05-21T05:30:48.795739Z","shell.execute_reply":"2024-05-21T05:30:48.804306Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Decoder","metadata":{}},{"cell_type":"code","source":"#Attention Decoder\nclass DecoderLSTM(nn.Module):\n    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n        super().__init__()\n        \n        #save the model param\n        self.vocab_size = vocab_size\n        self.attention_dim = attention_dim\n        self.decoder_dim = decoder_dim\n        \n        self.embedding = nn.Embedding(vocab_size,embed_size)\n        self.attention = Attention(encoder_dim,decoder_dim,attention_dim)\n        \n        self.init_h = nn.Linear(encoder_dim, decoder_dim)  \n        self.init_c = nn.Linear(encoder_dim, decoder_dim)  \n        self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True)\n        \n        self.logits_layer = nn.Linear(decoder_dim,vocab_size)\n        self.drop = nn.Dropout(drop_prob)\n        \n        \n    \n    def forward(self, features, captions):\n        \n        #vectorize the caption\n        embeds = self.embedding(captions)\n        \n        # Initialize LSTM state\n        h, c = self.init_hidden_state(features)  # (batch_size, decoder_dim)\n        \n        #get the seq length to iterate\n        seq_length = len(captions[0])-1 #Exclude the last one\n        batch_size = captions.size(0)\n        num_features = features.size(1)\n        \n        preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device)\n        alphas = torch.zeros(batch_size, seq_length,num_features).to(device)\n                \n        for s in range(seq_length):\n            alpha,context = self.attention(features, h,c)\n            lstm_input = torch.cat((embeds[:, s], context), dim=1)\n            h, c = self.lstm_cell(lstm_input, (h, c))\n                    \n            output = self.logits_layer(self.drop(h))\n            \n            preds[:,s] = output\n            alphas[:,s] = alpha  \n        \n        \n        return preds, alphas\n    \n    def generate_caption(self, features, max_len=20, vocab=None):\n        # Inference part\n        # Given the image features generate the captions\n\n        batch_size = features.size(0)\n        h, c = self.init_hidden_state(features)  # (batch_size, decoder_dim)\n\n        alphas = []\n\n        # Starting input\n        word = torch.tensor(vocab.str_to_index['<SOS>']).view(1, -1).to(device)\n        embeds = self.embedding(word)\n\n        captions = []\n\n        for i in range(max_len):\n            alpha, context = self.attention(features, h,c)\n\n            # Store the alpha score\n            alphas.append(alpha.cpu().detach().numpy())\n\n            lstm_input = torch.cat((embeds[:, 0], context), dim=1)\n            h, c = self.lstm_cell(lstm_input, (h, c))\n            output = self.logits_layer(self.drop(h))\n            output = output.view(batch_size, -1)\n\n            # Replace <UNK> token with the most probable word\n            predicted_word_idx = output.argmax(dim=1)\n            if predicted_word_idx.item() == vocab.str_to_index['<UNK>']:\n                _, next_highest = torch.topk(output, 2, dim=1)\n                predicted_word_idx = next_highest[:, 1]  # Select the second most probable word\n            # Save the generated word\n            captions.append(predicted_word_idx.item())\n\n            # End if <EOS detected>\n            if vocab.index_to_str[predicted_word_idx.item()] == \"<EOS>\":\n                break\n\n            # Send the generated word as the next caption\n            embeds = self.embedding(predicted_word_idx.unsqueeze(0))\n\n        # Convert the vocab idx to words and return sentence\n        return [vocab.index_to_str[idx] for idx in captions], alphas\n    \n    \n    def init_hidden_state(self, encoder_out):\n        mean_encoder_out = encoder_out.mean(dim=1)\n        h = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)\n        c = self.init_c(mean_encoder_out)\n        return h, c\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:30:51.631778Z","iopub.execute_input":"2024-05-21T05:30:51.632184Z","iopub.status.idle":"2024-05-21T05:30:51.652467Z","shell.execute_reply.started":"2024-05-21T05:30:51.632152Z","shell.execute_reply":"2024-05-21T05:30:51.651498Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,image_transformation,drop_prob=0.3):\n        super().__init__()\n        self.embed_size=embed_size\n        self.vocab_size=vocab_size\n        self.attention_dim=attention_dim\n        self.encoder_dim=encoder_dim\n        self.decoder_dim=decoder_dim\n        \n        self.encoder = EncoderCNN()\n        self.decoder = DecoderLSTM(\n            embed_size=self.embed_size,\n            vocab_size = self.vocab_size,\n            attention_dim=self.attention_dim,\n            encoder_dim=self.encoder_dim,\n            decoder_dim=self.decoder_dim\n        )\n        self.image_transformation=image_transformation\n        \n    def forward(self, images, captions):\n        features = self.encoder(images)\n        outputs = self.decoder(features, captions)\n        return outputs\n    \n    #generate caption\n    def get_caps_from_image(self,image,show_image=False):\n        features_tensors = self.image_transformation(image).unsqueeze(0)\n        #generate the caption\n        model.eval()\n        with torch.no_grad():\n            features = self.encoder(features_tensors.to(device))\n            caps,alphas = self.decoder.generate_caption(features,vocab=train_dataset.vocab)\n            caption = ' '.join(caps)\n            if show_image:\n                show_image(features_tensors[0],title=caption)\n        return caption,caps,alphas\n        \n        \n    def save_model(self,num_epochs):\n        model_state = {\n            'num_epochs':num_epochs,\n            'embed_size':self.embed_size,\n            'vocab_size':self.vocab_size,\n            'attention_dim':self.attention_dim,\n            'encoder_dim':self.encoder_dim,\n            'decoder_dim':self.decoder_dim,\n            'image_transformation':self.image_transformation,\n            'state_dict':self.state_dict()\n        }\n\n        torch.save(model_state,f'attention_model_state_{num_epochs}.pth')\n    \n    @staticmethod\n    def load_model(path):\n        # Define the path to your saved model state dictionary\n        model_state_path = path\n\n        # Load the state dictionary\n        model_state = torch.load(model_state_path,map_location=torch.device('cpu'))\n\n        # Initialize your model architecture\n        model = EncoderDecoder(\n            embed_size=model_state['embed_size'],\n            vocab_size=model_state['vocab_size'],\n            attention_dim=model_state['attention_dim'],\n            encoder_dim=model_state['encoder_dim'],\n            decoder_dim=model_state['decoder_dim'],\n            image_transformation=model_state['image_transformation']\n        )\n\n        # Load the state dictionary into the model\n        model.load_state_dict(model_state['state_dict'])\n\n        # If the model was trained on GPU and you want to use it on GPU\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = model.to(device)\n\n        # Ensure the model is in evaluation mode\n        model.eval()\n        return model\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:30:55.544369Z","iopub.execute_input":"2024-05-21T05:30:55.545203Z","iopub.status.idle":"2024-05-21T05:30:55.559593Z","shell.execute_reply.started":"2024-05-21T05:30:55.545172Z","shell.execute_reply":"2024-05-21T05:30:55.558721Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"len(train_dataset.vocab)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:46:14.020818Z","iopub.execute_input":"2024-05-17T14:46:14.021118Z","iopub.status.idle":"2024-05-17T14:46:14.032856Z","shell.execute_reply.started":"2024-05-17T14:46:14.021094Z","shell.execute_reply":"2024-05-17T14:46:14.031959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#init model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlearning_rate = 3e-4\nembed_size=300\nvocab_size = len(train_dataset.vocab)\nattention_dim=256\nencoder_dim=2048\ndecoder_dim=512\n\nmodel = EncoderDecoder(\n    embed_size=embed_size,\n    vocab_size = vocab_size,\n    attention_dim=attention_dim,\n    encoder_dim=encoder_dim,\n    decoder_dim=decoder_dim,\n    image_transformation=images_transforms\n).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=train_dataset.vocab.str_to_index[\"<PAD>\"])\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T04:56:42.121194Z","iopub.execute_input":"2024-05-21T04:56:42.121849Z","iopub.status.idle":"2024-05-21T04:56:43.760240Z","shell.execute_reply.started":"2024-05-21T04:56:42.121815Z","shell.execute_reply":"2024-05-21T04:56:43.759207Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"#helper function to save the model\ndef save_model(model,num_epochs):\n    model_state = {\n        'num_epochs':num_epochs,\n        'embed_size':embed_size,\n        'vocab_size':vocab_size,\n        'attention_dim':attention_dim,\n        'encoder_dim':encoder_dim,\n        'decoder_dim':decoder_dim,\n        'state_dict':model.state_dict()\n    }\n\n    torch.save(model_state,f'attention_model_state_{num_epochs}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:46:15.037923Z","iopub.execute_input":"2024-05-17T14:46:15.038214Z","iopub.status.idle":"2024-05-17T14:46:15.043295Z","shell.execute_reply.started":"2024-05-17T14:46:15.038189Z","shell.execute_reply":"2024-05-17T14:46:15.042423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1\nprint_every = 100\n\n\nfor epoch in range(1,num_epochs+1):   \n    for idx, (image, captions) in enumerate(iter(data_loader)):\n        image,captions = image.to(device),captions.to(device)\n\n        # Zero the gradients.\n        optimizer.zero_grad()\n\n        # Feed forward\n        outputs,attentions = model(image, captions)\n\n        # Calculate the batch loss.\n        targets = captions[:,1:]\n        loss = criterion(outputs.view(-1, vocab_size), targets.reshape(-1))\n        \n        # Backward pass.\n        loss.backward()\n\n        # Update the parameters in the optimizer.\n        optimizer.step()\n\n        if (idx+1)%print_every == 0:\n            print(\"Epoch: {} loss: {:.5f}\".format(epoch,loss.item()))\n            \n            \n            #generate the caption\n            model.eval()\n            with torch.no_grad():\n                dataiter = iter(data_loader)\n                img,_ = next(dataiter)\n                features = model.encoder(img[0:1].to(device))\n                caps,alphas = model.decoder.generate_caption(features,vocab=train_dataset.vocab)\n                caption = ' '.join(caps)\n#                 show_image(img[0],title=caption)\n            print(caption)\n            model.train()\n    if epoch % 10 ==0 :\n        #save the latest model\n        model.save_model(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:29:01.050828Z","iopub.execute_input":"2024-05-21T05:29:01.051218Z","iopub.status.idle":"2024-05-21T05:29:50.913146Z","shell.execute_reply.started":"2024-05-21T05:29:01.051187Z","shell.execute_reply":"2024-05-21T05:29:50.911868Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):   \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (image, captions) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(data_loader)):\n\u001b[0;32m----> 7\u001b[0m         image,captions \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,captions\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Zero the gradients.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# import requests\n# import matplotlib.pyplot as plt\n# from PIL import Image\n# from io import BytesIO\n\n# # URL of the image you want to download from Google Images\n# image_url = \"https://toppng.com/uploads/preview/birds-cars-nature-pool-road-wallpaper-11556236672boim4gbcsv.jpg\"  # Replace this with the actual URL\n\n# # Send a GET request to the image URL\n# response = requests.get(image_url)\n\n# # Check if the request was successful\n# if response.status_code == 200:\n#     # Open the image using PIL\n#     image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    \n#     # Display the image using Matplotlib\n#     plt.imshow(image)\n#     plt.axis('off')  # Turn off axis\n#     plt.show()\n# else:\n#     print(\"Failed to download the image. Status code:\", response.status_code)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:47:06.348517Z","iopub.status.idle":"2024-05-17T14:47:06.348934Z","shell.execute_reply.started":"2024-05-17T14:47:06.348710Z","shell.execute_reply":"2024-05-17T14:47:06.348724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_image(img, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    \n    #unnormalize \n    img[0] = img[0] * 0.229\n    img[1] = img[1] * 0.224 \n    img[2] = img[2] * 0.225 \n    img[0] += 0.485 \n    img[1] += 0.456 \n    img[2] += 0.406\n    \n    img = img.numpy().transpose((1, 2, 0))\n    \n    \n    plt.imshow(img)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated","metadata":{"execution":{"iopub.status.busy":"2024-05-17T14:47:06.350849Z","iopub.status.idle":"2024-05-17T14:47:06.351398Z","shell.execute_reply.started":"2024-05-17T14:47:06.351156Z","shell.execute_reply":"2024-05-17T14:47:06.351177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load existing model","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Define the path to your saved model state dictionary\nmodel_state_path = \"/kaggle/input/model-image-captioning-100-batch-size/attention_model_state_200.pth\"\nmodel=EncoderDecoder.load_model(model_state_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:31:06.303168Z","iopub.execute_input":"2024-05-21T05:31:06.303819Z","iopub.status.idle":"2024-05-21T05:31:07.167078Z","shell.execute_reply.started":"2024-05-21T05:31:06.303787Z","shell.execute_reply":"2024-05-21T05:31:07.166272Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test the model","metadata":{}},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n\ndef calculate_bleu_score(reference_captions, generated_captions, ngram_order=4):\n    smoothie = SmoothingFunction().method1  # Define smoothing function\n    return corpus_bleu([[ref] for ref in reference_captions], generated_captions, weights=(1.0/ngram_order,)*ngram_order, smoothing_function=smoothie)\n\ndef get_reference_captions(test_image_ids, captions_df):\n    reference_captions = []\n    for img_id in test_image_ids:\n        # Get captions for the current image ID\n        captions_for_img = captions_df[captions_df['image'] == img_id]['caption'].tolist()\n        reference_captions.append(captions_for_img)\n    return reference_captions\n\ndef test_model_on_test_set(model, test_image_ids, captions_df,images_dir, vocab):\n    all_generated_captions = []\n    for img_id in test_image_ids:\n        # Get captions for the current image ID\n        captions_for_img = captions_df[captions_df['image'] == img_id]['caption'].tolist()\n        # Load the image\n        img_location = os.path.join(images_dir, img_id)\n        img = Image.open(img_location).convert(\"RGB\")\n        # Generate caption\n        caption, _, _ = model.get_caps_from_image(img)\n        all_generated_captions.append(caption.split())\n    return all_generated_captions\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:19:17.142168Z","iopub.execute_input":"2024-05-21T05:19:17.142883Z","iopub.status.idle":"2024-05-21T05:19:17.153892Z","shell.execute_reply.started":"2024-05-21T05:19:17.142848Z","shell.execute_reply":"2024-05-21T05:19:17.152869Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Get unique test image IDs\ntest_image_ids = test_df['image'].unique()\n\n# Test model on the test set\ngenerated_captions = test_model_on_test_set(model, test_image_ids, captions_df,data_location+\"/Images\" ,train_dataset.vocab)\ntokenized_generated_caption__ = [[sentence for sentence in group[:-1]] for group in generated_captions]\n\n# Get reference captions for the test set\nreference_captions = get_reference_captions(test_image_ids, captions_df)\ntokenized_reference_captions__ = [[sentence.split() for sentence in group] for group in reference_captions]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:31:54.554957Z","iopub.execute_input":"2024-05-21T05:31:54.555815Z","iopub.status.idle":"2024-05-21T05:32:58.057344Z","shell.execute_reply.started":"2024-05-21T05:31:54.555783Z","shell.execute_reply":"2024-05-21T05:32:58.056440Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T13:07:15.928357Z","iopub.execute_input":"2024-05-20T13:07:15.928708Z","iopub.status.idle":"2024-05-20T13:07:15.933463Z","shell.execute_reply.started":"2024-05-20T13:07:15.928680Z","shell.execute_reply":"2024-05-20T13:07:15.932541Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Calculate overall BLEU scores with smoothing\nbleu1 = corpus_bleu(tokenized_reference_captions__, tokenized_generated_caption__, weights=(1, 0, 0, 0))\nbleu2 = corpus_bleu(tokenized_reference_captions__, tokenized_generated_caption__, weights=(0.5, 0.5, 0, 0))\nbleu3 = corpus_bleu(tokenized_reference_captions__, tokenized_generated_caption__, weights=(0.33, 0.33, 0.33, 0))\nbleu4 = corpus_bleu(tokenized_reference_captions__, tokenized_generated_caption__, weights=(0.25, 0.25, 0.25, 0.25))\n\n# Print the BLEU scores\nprint(f'Overall BLEU-1: {bleu1:.4f}')\nprint(f'Overall BLEU-2: {bleu2:.4f}')\nprint(f'Overall BLEU-3: {bleu3:.4f}')\nprint(f'Overall BLEU-4: {bleu4:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:33:22.706958Z","iopub.execute_input":"2024-05-21T05:33:22.707852Z","iopub.status.idle":"2024-05-21T05:33:25.072887Z","shell.execute_reply.started":"2024-05-21T05:33:22.707820Z","shell.execute_reply":"2024-05-21T05:33:25.071972Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Overall BLEU-1: 0.5250\nOverall BLEU-2: 0.3182\nOverall BLEU-3: 0.2005\nOverall BLEU-4: 0.1214\n","output_type":"stream"}]},{"cell_type":"code","source":"regenerated_captions=[\" \".join(sentence[:-1]) for sentence in generated_captions]","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:00:31.035249Z","iopub.execute_input":"2024-05-20T07:00:31.035815Z","iopub.status.idle":"2024-05-20T07:00:31.060262Z","shell.execute_reply.started":"2024-05-20T07:00:31.035787Z","shell.execute_reply":"2024-05-20T07:00:31.059157Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"['a group of people are riding horses in a field .',\n 'a woman in a white shirt and a woman in a white shirt and a crowd .',\n 'a motorcycle racer is driving a motorcycle .',\n 'a man is sitting on a bench .',\n 'a man is riding a bike on a bike .',\n 'a black dog is running through the water .',\n 'a man is holding a camera while another man is standing on a cellphone .',\n 'a baseball player in a red uniform is running in the air .',\n 'a man in a red uniform is playing soccer .',\n 'a black dog is running through the water .',\n 'a motorcycle racer is driving a race car .',\n 'a man in a black shirt and a black shirt is holding a camera .',\n 'a man in a blue hat and a hat is standing in front of a crowd .',\n 'a boy in a red shirt is jumping on a trampoline .',\n 'a boy in a red shirt is jumping up to catch a red toy .',\n 'a man in a green shirt is standing in front of a crowd of people .',\n 'a man in a black and white dog is running through the water .',\n 'a group of children are playing in a field .',\n 'a black and white dog is running through a grassy area .',\n 'a boy plays in a pool .',\n 'a man in a blue helmet rides his bike on a bike .',\n 'a man in a yellow kayak is riding a red bike .',\n 'a woman in a blue shirt and blue shorts is walking on a beach .',\n 'a man in a red shirt is doing a trick on a ramp .',\n 'a race car is driving through the dirt .',\n 'a young boy wearing a blue shirt and goggles is wearing a blue shirt and goggles .',\n 'a black and white dog is running through a grassy area .',\n 'two dogs are running through a field .',\n 'a person on a bike is riding a bike .',\n 'a woman in a white shirt and white pants is walking down a street .',\n 'a dog jumps up to catch a frisbee .',\n 'a girl in a white shirt is sitting on a bench in a park .',\n 'a man is climbing a rock .',\n 'a dog is running through the water .',\n 'a man in a white shirt and a white shirt is running on a field .',\n 'a white dog is laying on a white carpet .',\n 'a man and a woman are standing in front of a building .',\n 'a man in a red helmet is riding a bike down a dirt path .',\n 'a group of people sit on a bench .',\n 'a boy in a red shirt is running on a green field .',\n 'a man in a black shirt and a black shirt is jumping up a jump .',\n 'a brown dog is laying on a leash .',\n 'a black dog is running through the water .',\n 'a girl in a black shirt is jumping on a trampoline .',\n 'a person is climbing a rock .',\n 'a man in a red shirt is standing on a mountain .',\n 'a woman in a white shirt and a black shirt is standing in front of a crowd .',\n 'a man in a yellow shirt is jumping up to catch a ball .',\n 'a man is sitting on a boat with a boat .',\n 'a boy in a blue shirt is holding a stick .',\n 'a man in a white shirt and white shorts is standing on a white bench .',\n 'a man in a white shirt is jumping up a trick in front of a white building .',\n 'a man in a white shirt and white shorts is standing on a trampoline .',\n 'a boy in a blue shirt is standing in the water .',\n 'a boy in a blue shirt is walking down a sidewalk .',\n 'a man in a red shirt and white shorts is jumping up in the air .',\n 'a soccer player in a red uniform is running on the field .',\n 'a young boy wearing a blue shirt is holding a stick in his mouth .',\n 'a man in a blue shirt is walking down a street .',\n 'a dog is running through the water .',\n 'a man is standing on a rock overlooking a mountain .',\n 'a man in a blue shirt is jumping over a rope in a forest .',\n 'a man in a red and white helmet is riding a motorcycle .',\n 'a man is riding a bike on a bike .',\n 'a woman in a white dress and a woman in a white dress .',\n 'a black dog runs through the water .',\n 'a man is doing a trick on a ramp .',\n 'a white dog running through the grass .',\n 'a group of men in red and white uniforms are standing in front of a crowd .',\n 'a woman in a dress and a woman in a dress .',\n 'a young boy with a blue shirt is holding a baby in a blue dress .',\n 'four children are playing in a park .',\n 'a snowboarder is doing a trick on a ramp .',\n 'a man in a blue shirt and a blue shirt is standing on a bench .',\n 'a man in a red helmet rides a bike through a forest .',\n 'a group of people are riding horses .',\n 'a boy in a red shirt is jumping in a gym .',\n 'a man in a yellow shirt is riding a horse .',\n 'a man in a red shirt is standing on a mountain .',\n 'a man and a woman are playing in a park .',\n 'a woman in a red shirt and a woman in a blue dress .',\n 'a woman in a white dress and a white dog is running through a field .',\n 'a man in a white shirt and a woman in a blue shirt and a woman in a blue',\n 'a man in a blue shirt is jumping on a rock wall .',\n 'a black and white dog is jumping over a hurdle .',\n 'a man in a black shirt is sitting on a bench .',\n 'a man in a red jacket is riding a red bike .',\n 'a white dog is running through the water .',\n 'a dog jumps over a hurdle .',\n 'a man is jumping on a skateboard .',\n 'a group of young girls in bathing suits are playing in the water .',\n 'a motorcyclist in a red helmet is riding a dirt bike .',\n 'a man in a blue shirt is doing a trick on a ramp .',\n 'a man is riding a bike on a dirt road .',\n 'a man in a blue shirt is riding a horse on a horse .',\n 'a man in a red jacket is standing on a snowy mountain .',\n 'a man is standing on a beach .',\n 'a boy in a blue bathing suit is swimming in the pool .',\n 'a boy is swimming in the pool .',\n 'a woman in a black hat is riding a bike .',\n 'a boy in a blue shirt is riding a skateboard down a ramp .',\n 'a dog is running through the grass .',\n 'a group of people are standing in a field .',\n 'a white dog is running on a grassy field .',\n 'a man in a blue shirt and a hat is walking on the beach .',\n 'a brown dog is running through a field .',\n 'a brown dog is running through the water .',\n 'a surfer in a red jacket is riding a wave .',\n 'a group of people are standing on a sidewalk .',\n 'a man in a white shirt is doing a trick on a skateboard .',\n 'a person is jumping over a ramp .',\n 'a black and white dog is running through a field .',\n 'a black and white dog is running through a field .',\n 'two dogs are running through a lake .',\n 'a man in a blue shirt and a black shirt and a black shirt and a white shirt and',\n 'a group of people are playing in a field .',\n 'a black dog is running through a grassy field .',\n 'a girl in a pink shirt is smiling .',\n 'a group of people are sitting on a bench .',\n 'a black and white dog is running through a field .',\n 'a woman in a red shirt and a woman in a red shirt and a woman in a red',\n 'a woman in a black dress is standing in front of a crowd of people .',\n 'a man in a red shirt is surfing on a surfboard .',\n 'a boy in a blue shirt is running through the grass .',\n 'a man in a black shirt and a black shirt is walking on a sidewalk .',\n 'a man with a mohawk and white shirt is holding a microphone .',\n 'a man and a woman in a black shirt and a woman in a black shirt .',\n 'a black dog is running through a grassy area .',\n 'a man in a red shirt and a helmet and a helmet and a helmet .',\n 'a man is doing a trick on a skateboard .',\n 'a black dog is running through a grassy area .',\n 'a man in a black hat and a hat and a woman in a black jacket .',\n 'a man in a red shirt is sitting on a couch .',\n 'a dog is running through the water .',\n 'a man in a black shirt and a hat is standing on the beach .',\n 'a boy in a red shirt is jumping over a playground .',\n 'a black dog is running through a grassy field .',\n 'a hockey player in a red uniform is running in the air .',\n 'a group of people are playing instruments .',\n 'a girl in a pink dress is holding a stick .',\n 'a man is sitting on a subway train .',\n 'a surfer is surfing on a wave .',\n 'a group of people are sitting on a stage .',\n 'a man in a red helmet rides a bike in the air .',\n 'a man is jumping off a ramp .',\n 'a man in a white shirt and a black dog are standing on a beach .',\n 'a group of people are standing in front of a white tent .',\n 'a dog is laying on a bed .',\n 'a man in a black jacket is holding a cigarette .',\n 'a woman in a black dress is holding a woman in a black dress .',\n 'a man is riding a bike on a mountain .',\n 'a man is doing a bicycle trick on a bike .',\n 'a brown dog is running through a field .',\n 'a woman in a pink shirt is walking down a sidewalk .',\n 'a man and woman are posing for a picture .',\n 'a woman in a white dress and a white shirt is holding a baby in a white dress .',\n 'a man is doing a trick on a bike .',\n 'a man in a yellow shirt is standing on a skateboard .',\n 'a boy in a blue shirt is kicking a soccer ball .',\n 'a boy in a red uniform is running on the grass .',\n 'a man in a blue shirt is sitting on a bench .',\n 'a young boy wearing a blue shirt is running on a sidewalk .',\n 'a boy in a white uniform playing soccer .',\n 'a girl in a red shirt is jumping over a white bar .',\n 'a man is swimming in a pool .',\n 'a man in a black shirt and a white shirt and a black shirt and a white shirt and',\n 'a group of people are walking down a street .',\n 'a boy in a white uniform is running on a field .',\n 'a man in a red shirt is jumping into a lake .',\n 'a group of people are running in a field .',\n 'a group of people are standing in front of a large group of people .',\n 'a boy rides a unicycle on a bike .',\n 'a group of people are standing in front of a large group of people .',\n 'a man in a red shirt is riding a bike in a red and white helmet .',\n 'a man in a black wetsuit is surfing .',\n 'two dogs are playing in a pond .',\n 'a man in a yellow shirt is riding a bike in the air .',\n 'a boy swinging on a swing .',\n 'a man in a white shirt and a white shirt and a black shirt is walking down a road',\n 'a woman in a white dress and a white dress is holding a red and white dress .',\n 'a boy in a red shirt is jumping on a skateboard .',\n 'a brown and white dog is jumping over a hurdle .',\n 'a girl in a pink shirt and a pink shirt is standing on a rock wall .',\n 'a little boy is holding a red shirt .',\n 'a man in a black hat and a hat and a hat .',\n 'a boy in a red shirt is sliding down a slide .',\n 'a group of people dressed in costumes and a woman in a red dress .',\n 'a bride and groom are standing in front of a white dress .',\n 'a woman in a white dress is standing on a sidewalk .',\n 'a man sitting on a bench with a wooden bench .',\n 'a man in a blue shirt is holding a baby in a blue shirt .',\n 'a black dog is running through the water .',\n 'a man is standing in front of a large crowd of people .',\n 'a man in a blue shirt and a woman in a white shirt and a woman in a crowd',\n 'a man in a black shirt and a black hat is holding a camera .',\n 'a surfer in a wetsuit is surfing on a surfboard .',\n 'a man is standing on a skateboard .',\n 'a man is standing on a skateboard with a graffiti wall .',\n 'a child in a red shirt is jumping over a pole .',\n 'a boy in a black shirt is jumping over a rock .',\n 'a group of people are posing for a picture .',\n 'a little girl in a red shirt is holding a red and white toy .',\n 'a man in a white shirt is standing on a white dog with a white dog .',\n 'a dog is running through a stream .',\n 'a man in a blue wetsuit is riding a wave .',\n 'a group of people sit on a bench in front of a building .',\n 'a man in a black shirt is holding a black and white dog .',\n 'two dogs are running on a beach .',\n 'a black dog is running on the beach .',\n 'a man in a red shirt is driving a dirt bike .',\n 'a boy in a blue shirt is jumping on a swing .',\n 'a brown dog is running through a grassy field .',\n 'a man in a black shirt and a black shirt and a black shirt and a woman in a',\n 'a man in a black shirt is standing on a stage .',\n 'a group of people are gathered at a table .',\n 'a group of children playing on a swing .',\n 'a man in a white shirt is jumping in front of a building .',\n 'a skateboarder is jumping over a ramp .',\n 'a man in a helmet rides a bike in a forest .',\n 'a man is sitting on a horse .',\n 'a group of people are standing on a track .',\n 'a group of people are standing in front of a large building .',\n 'a group of people are standing in front of a group of people .',\n 'a boy in a red shirt is jumping on a skateboard .',\n 'a man in a white uniform is running on a field .',\n 'a young boy wearing a green shirt is standing in a forest .',\n 'a black and white dog is running through the grass .',\n 'a boy in a red shirt is riding a skateboard on a skateboard .',\n 'a man in a black hat is riding a bike on a skateboard .',\n 'a skateboarder is jumping in the air .',\n 'a dog is running through the water .',\n 'a woman wearing a pink hat and a hat is holding a camera .',\n 'a boy in a blue shirt is running on the beach .',\n 'a man in a white shirt is running on a field .',\n 'a girl in a red shirt and a blue shirt is holding a red and white dog .',\n 'a man in a red hat is holding a red and white hat .',\n 'a dog is running through the grass .',\n 'a white dog is standing on a rock face .',\n 'a man in a yellow shirt is riding a bike down a hill .',\n 'a dog is running through the grass .',\n 'a group of people are standing in front of a large building .',\n 'a dog is running through the water .',\n 'a man in a red shirt is holding a stick in his mouth .',\n 'a group of people are racing on a dirt road .',\n 'a man and a woman in a white shirt and a white shirt and a black dog are walking',\n 'a black and brown dog is running on a grassy field .',\n 'a woman in a blue shirt and a woman in a blue dress .',\n 'a boy in a black shirt is holding a baby in a black shirt .',\n 'a girl in a bathing suit is jumping into the water .',\n 'a brown and white dog is running through the snow .',\n 'a man is standing on a track with a large brown dog .',\n 'a man in a red shirt and a woman in a white shirt and a woman in a red',\n 'a man in a black shirt is riding a bicycle in a city street .',\n 'a woman in a white dress is holding a baby in a white dress .',\n 'a boy is jumping into a pool .',\n 'a woman in a red jacket is riding a horse .',\n 'a dog jumps over a frisbee in the snow .',\n 'a dog runs through the grass .',\n 'a group of people are walking on a beach .',\n 'a woman in a blue shirt and a blue shirt and a woman in a blue dress .',\n 'a dog is running through the water .',\n 'a dog jumps over a hurdle .',\n 'a dog is swimming in the water .',\n 'a man in a red shirt and a woman in a black jacket and a black jacket is walking',\n 'a woman in a black dress and a woman in a black dress .',\n 'a dog is playing with a white dog in a pool .',\n 'two dogs are running in the grass .',\n 'a man in a blue shirt is standing on a beach .',\n 'a black dog is running through the water .',\n 'a boy in a blue shirt is jumping on a swing .',\n 'a brown dog is laying on a leash .',\n 'a young girl in a red shirt is running through a playground .',\n 'a woman in a black and white shirt and a black hat and a backpack is standing on a',\n 'a man is standing on a rock in the woods .',\n 'a black dog is running through the snow .',\n 'a brown dog is running through the grass .',\n 'a boy in a blue shirt is jumping into the water .',\n 'a boy rides a bike on a ramp .',\n 'a baby in a blue shirt is sitting on a plastic toy .',\n 'a woman in a black shirt and a woman in a black dress .',\n 'a man in a black and white shirt is jumping over a white surfboard .',\n 'a man is jumping over a railing in a city .',\n 'a young boy in a blue shirt is standing in a forest .',\n 'a girl in a pink dress is holding a baby in a pink dress .',\n 'a boy in a blue shirt and a blue shirt is standing on a playground .',\n 'a young boy is jumping on a trampoline .',\n 'a man in a black suit and a black hat and a woman in a black jacket .',\n 'a man and a woman wearing sunglasses and a black shirt .',\n 'a black dog is jumping over a hurdle .',\n 'a man is doing a trick on a ramp .',\n 'a man is sitting in a room with a red toy in a room .',\n 'a man is doing a trick on a ramp .',\n 'a group of people are in a colorful plastic - colored - round - round - round - colored',\n 'a skateboarder is jumping over a ramp .',\n 'a man is doing a trick on a bike .',\n 'a man in a white helmet is riding a bike .',\n 'a dog jumps over a stream of a large pile of trees .',\n 'a brown and white dog is jumping up to catch a ball .',\n 'a man in a white uniform is playing a baseball game .',\n 'a dog and a dog running on the sand .',\n 'a girl in a pink dress is playing with a pink toy .',\n 'a group of people are standing in front of a crowd .',\n 'a boy in a blue shirt is swimming in a pool .',\n 'a boy in a red shirt is holding a toy car .',\n 'a young boy is swinging on a swing .',\n 'a boy in a swimming trunks is jumping into the water .',\n 'a little boy in a red shirt is running through a grassy field .',\n 'a group of people are standing in front of a crowd .',\n 'a woman in a white shirt and a woman in a white shirt and a white shirt and a',\n 'a little boy in a red shirt is jumping over a green and white dog .',\n 'a man in a red shirt is riding a bike down a trail .',\n 'a man in a red shirt is jumping into the water .',\n 'a rugby player in a red uniform is running in the air .',\n 'a woman in a black shirt is standing in front of a store .',\n 'a man in a black shirt is riding a skateboard down a ramp .',\n 'a group of people are riding a boat on a boat .',\n 'a man in a yellow shirt is surfing in the water .',\n 'a group of people are standing in front of a large building .',\n 'a group of people sit on a bench .',\n 'two women are posing for a picture .',\n 'a man in a blue shirt is sitting on a rock wall .',\n 'a man on a bike is riding a bike in the woods .',\n 'a girl swinging on a swing .',\n 'a skateboarder jumps over a ramp .',\n 'a man is flying over a wave .',\n 'a woman in a white dress and a brown dog running in a field .',\n 'a man in a red shirt is riding a bike in the air .',\n 'a group of people are sitting on a bench .',\n 'a man in a red helmet is riding a bike in the air .',\n 'a man in a black shirt is standing in front of a large building .',\n 'a brown dog is running on a sidewalk .',\n 'a group of people are standing in a field .',\n 'a group of women in a costume and a woman in a black dress .',\n 'a girl in a red shirt is playing with a ball .',\n 'a man is standing on a mountain .',\n 'a woman in a pink shirt is holding a baby in a chair .',\n 'a girl in a pink shirt is jumping up to a woman in a white shirt .',\n 'a dog is running on a beach .',\n 'a man in a black jacket is standing on a bench .',\n 'a little girl is playing with a small child in a room .',\n 'a man in a white shirt is standing in front of a store .',\n 'a group of people are dancing in a white room .',\n 'a man is riding a bike on a beach .',\n 'a woman in a pink shirt and a woman in a blue shirt and a blue shirt and a',\n 'a boy is climbing a rock .',\n 'a girl in a pink dress is running through the grass .',\n 'a skateboarder doing a trick on a ramp .',\n 'a man with a white shirt is looking at a man in a black shirt .',\n 'a man is standing on a hill with a mountain in the background .',\n 'a white dog is running through a grassy field .',\n 'a man in a black jacket and a black hat and a black hat and a black jacket .',\n 'a man in a red shirt is standing on a wooden bench .',\n 'a woman in a pink shirt is standing in front of a crowd of people .',\n 'a man in a red shirt is jumping up a jump .',\n 'a little boy is playing with a ball in a field .',\n 'a dog with a red collar is running on a leash .',\n 'a man in a white shirt and a woman in a white shirt and a white shirt is standing',\n 'a woman in a black shirt is holding a drink in a blue shirt .',\n 'a boy in a blue shirt is jumping on a trampoline .',\n 'a woman in a red dress is walking down a road .',\n 'a boy in a blue bathing suit is jumping into a pool .',\n 'a dog runs through the grass .',\n 'a man in a yellow shirt is jumping over a pole .',\n 'a group of people stand in front of a store .',\n 'a man in a black hat and a hat and a hat .',\n 'a man in a blue shirt and a black shirt and a woman in a crowd .',\n 'a little girl in a blue shirt is smiling .',\n 'a group of people in a red and white helmet and a black and white helmet is standing in',\n 'a man in a red shirt is holding a red and white balloon .',\n 'a man in a black shirt and a woman in a black shirt and a woman in a black',\n 'a man in a black jacket and a black jacket is standing on a sidewalk .',\n 'a dog runs through the snow .',\n 'a dog runs through the water .',\n 'a boy in a baseball uniform is playing a baseball game .',\n 'a man in a blue shirt is holding a ball in a ring .',\n 'a group of people sitting on a bench .',\n 'a man in a blue shirt and a woman in a black shirt and a woman in a blue',\n 'a group of people are racing around a track .',\n 'two dogs are playing with a white dog .',\n 'a young boy wearing a yellow shirt is standing on a sidewalk .',\n 'a woman in a red dress and a black dress is wearing a red dress .',\n 'a little boy in a green shirt is jumping over a tree .',\n 'a man in a black jacket is standing on a city street .',\n 'two dogs are running through the water .',\n 'a white car is driving a race car .',\n 'a girl in a blue shirt is climbing a tree .',\n 'three people are standing in the grass .',\n 'a boy is swimming in a pool .',\n 'a man in a yellow jacket is riding a yellow kayak in the water .',\n 'a group of people are standing in front of a crowd of people .',\n 'a man is standing in front of a race car .',\n 'a man in a yellow shirt and a blue shirt is walking down a sidewalk .',\n 'a man in a blue shirt is jumping up a trick in front of a building .',\n 'a group of people are posing for a picture .',\n 'a man in a white shirt and a woman in a white dress .',\n 'a woman in a red dress is holding a red and white and red shirt .',\n 'a dog jumps over a hurdle .',\n 'a man and a woman sitting on a bench .',\n 'a boy in a red shirt is jumping over a playground .',\n 'a man in a black shirt and a black shirt and a woman in a black shirt and a',\n 'a man in a black jacket and a black hat and a black jacket is standing in front of',\n 'a woman in a red costume is walking down a street .',\n 'a child in a swimming pool .',\n 'a man in a black hat and a black hat and a woman in a black jacket .',\n 'a woman in a red shirt and a red shirt is holding a red and white umbrella .',\n 'a group of people in a red dress and a woman in a white dress .',\n 'a young boy is jumping in a park .',\n 'a little girl in a pink shirt is sitting on a grassy lawn .',\n 'a boy is jumping into a pool .',\n 'a woman in a red shirt and a backpack is standing on a rock .',\n 'a woman in a blue shirt and a backpack is standing on a mountain .',\n 'a man in a black jacket is riding a bike on a skateboard .',\n 'a man in a white shirt and a white shirt is standing in a city street .',\n 'a man in a blue shirt is jumping over a ramp .',\n 'a man is jumping into the water .',\n 'a man in a red shirt and a hat and a hat .',\n 'a man and a woman are standing in front of a large mountain .',\n 'a man in a red jacket is walking on a snowy hill .',\n 'a man is standing on a boat with a boat in the background .',\n 'a girl in a pink shirt is standing on a couch .',\n 'a skateboarder is jumping over a rail .',\n 'a man in a red helmet rides a bike .',\n 'a man in a white shirt and white shorts is playing with a ball in a field .',\n 'a brown dog is running through the snow .',\n 'a man in a black shirt is standing in front of a crowd of people .',\n 'a person in a red jacket is standing on a rock .',\n 'a man is riding a yellow bike in a lake .',\n 'a group of people are sitting on a bench .',\n 'a group of people are standing in front of a crowd .',\n 'a group of people are gathered around a group of people .',\n 'a man in a red jacket is walking through snow .',\n 'a black dog is running through a forest .',\n 'a man in a black shirt and a black hat is standing on a bench .',\n 'a man in a red helmet is riding a bike .',\n 'a group of people are standing in front of a large crowd .',\n 'a group of people are standing in front of a large white tent .',\n 'a man in a blue shirt is climbing a rock .',\n 'a woman in a red shirt and a black hat is sitting on a bench .',\n 'a group of people are playing in a field .',\n 'a boy in a blue shirt is running on a white and white uniform .',\n 'a brown dog is running through the water .',\n 'a dog runs across the grass .',\n 'a man in a black helmet rides a bike in a forest .',\n 'a skateboarder is jumping in the air .',\n 'a little girl in a pink shirt is standing on a tree .',\n 'a man in a black shirt is sitting on a car .',\n 'people are gathered in a city street .',\n 'a man in a black shirt is doing a trick on a skateboard .',\n 'a man in a white shirt is jumping over a white bar .',\n 'a dirt bike rider is jumping over a dirt track .',\n 'a small dog is running through the snow .',\n 'a man in a white jacket is standing on a snowy mountain .',\n 'a little girl in a pink shirt and a white shirt and a black shirt and a white shirt',\n 'a man in a white shirt is holding a baby in a chair .',\n 'a boy in a blue shirt is jumping into a pool .',\n 'a man in a red shirt is standing on a rock overlooking a rocky area .',\n 'a boy in a yellow shirt is swimming in a pool .',\n 'a man is riding a bike in the air .',\n 'a bird is flying over a rocky area .',\n 'a white bird is flying through the air .',\n 'a young girl in a blue shirt is standing on a sidewalk .',\n 'two children are playing in a field .',\n 'two people are standing in the water .',\n 'a man is standing on a beach .',\n 'a woman in a blue shirt is standing on a rock .',\n 'a boy in a red shirt is riding a bike down a road .',\n 'a young boy is running on a sidewalk .',\n 'a man in a blue shirt is walking down a sidewalk .',\n 'a man and a woman are posing for a picture .',\n 'a girl in a pink dress is holding a baby in a red dress .',\n 'a man in a blue shirt is riding a bike on a bike .',\n 'a man in a white shirt is standing on a train .',\n 'a woman in a pink dress is sitting on a bench in a park .',\n 'a group of people are sitting on a bench with a white and white dog .',\n 'a black and white dog is running through the water .',\n 'a man in a red shirt riding a bike .',\n 'a person in a blue and white helmet is riding a red bike in the snow .',\n 'a boy in a blue shirt is riding a bike .',\n 'a man is jumping into the air on a beach .',\n 'a man in a white shirt and a dog running through a field .',\n 'a woman in a red and white uniform is holding a sign .',\n 'a group of people are sitting in a green and white tent .',\n 'a man in a blue shirt is riding a bike on a dirt bike .',\n 'a man in a blue shirt is standing on a bench with a sign .',\n 'a man in a red shirt is sitting at a table with a table in a restaurant .',\n 'a group of people are standing in front of a large building .',\n 'a girl in a pink outfit is sitting on a bench .',\n 'a man in a blue wetsuit is surfing on a surfboard .',\n 'a boy is jumping over a table in a park .',\n 'a man in a blue shirt is jumping over a skateboard .',\n 'a man in a blue shirt is sitting on a bench .',\n 'a black and white dog is running through a grassy field .',\n 'a man in a red jacket is skiing down a snowy hill .',\n 'a man in a black shirt and a black hat and a woman are standing in front of a',\n 'a black dog is jumping through the water .',\n 'a boy in a red shirt is running on a dirt road .',\n 'a young girl in a white dress and a white shirt is running through a grassy area .',\n 'a man is standing in front of a large building .',\n 'a boy in a swimming pool is standing in a pool .',\n 'a boy in a blue shirt is jumping over a ramp .',\n 'a snowboarder is jumping through the air .',\n 'a black dog is running through the water .',\n 'a small child in a green shirt is holding a toy .',\n 'a soccer player in a black uniform is running in the air .',\n 'a man in a red shirt and a white hat is walking down a street .',\n 'a dog is running through the water .',\n 'a man and a woman are sitting on a beach .',\n 'a brown dog is running through a forest .',\n 'a young boy in a black shirt is swimming in the water .',\n 'a group of people are standing in front of a christmas tree .',\n 'a white dog is running through the water .',\n 'a group of people are walking down a street .',\n 'a dog jumps over a hurdle .',\n 'a group of people are standing in front of a large crowd .',\n 'a man in a blue shirt and a woman in a blue shirt and a woman in a blue',\n 'a dog jumps over a dock .',\n 'a woman in a white dress and white shirt is holding a white bag .',\n 'a man in a red helmet rides a bike .',\n 'a man in a red jacket is riding a skateboard down a ramp .',\n 'a girl in a blue dress is standing in front of a blue tent .',\n 'a woman in a white dress and a woman in a white dress .',\n 'a man and a woman are sitting in the water .',\n 'a group of people are standing on a beach .',\n 'a large white bird is flying through the air .',\n 'a man in a red shirt and a woman in a red costume .',\n 'a man in a red shirt is riding a dirt bike .',\n 'a man in a red jacket is walking through a lake .',\n 'a boy is jumping on a swing .',\n 'a group of children play in a field .',\n 'a group of people are standing in front of a crowd of people .',\n 'a brown and white dog runs through the grass .',\n 'a man in a green shirt and a brown dog is walking in a field .',\n 'a boy in a yellow shirt is riding a bike .',\n 'a woman in a black jacket is holding a baby in a black jacket .',\n 'a man in a yellow shirt is jumping into the air .',\n 'a man in a red shirt is riding a bike on a bike .',\n 'a dog is playing with a toy in its mouth .',\n 'a man in a blue helmet rides a bike in the woods .',\n 'a man and a woman wearing a black shirt and a black shirt .',\n 'a man and a woman in a black shirt and a woman are smiling .',\n 'a woman in a red dress is walking down a street .',\n 'a man in a blue shirt is jumping over a ramp .',\n 'a yellow car is driving a red kayak .',\n 'a man in a white shirt is playing a guitar .',\n 'a greyhound racing on a track .',\n 'a man in a blue shirt is riding a bicycle in a race .',\n 'a group of people are playing soccer .',\n 'a man in a blue shirt and blue shorts is running on a track .',\n 'a surfer is surfing in the ocean .',\n 'a man in a black shirt and a black shirt and a black shirt and a black shirt and',\n 'a black and white dog is running through a field .',\n 'a group of people are jumping into a pool .',\n 'a young boy is riding a bicycle on a bench .',\n 'a man in a blue shirt is driving a car .',\n 'two women in red shirts are standing in front of a car .',\n 'a dog jumps over a hurdle .',\n 'two men in white uniforms are playing in a white and white uniform .',\n 'a person in a green shirt is jumping over a green field .',\n 'a group of people are riding bikes on a road .',\n 'a man in a red shirt is riding a bike down a ramp .',\n 'a man in a blue shirt and a blue shirt is riding a bike in a parking lot .',\n 'a man in a white uniform is running in a field .',\n 'a dog runs through the grass .',\n 'a man in a black jacket is standing in front of a store .',\n 'a man in a black shirt and a woman in a white shirt and a white shirt and a',\n 'two dogs are running in a field .',\n 'a man in a black shirt and a black shirt and a black shirt and a black shirt and',\n 'a man in a blue shirt is jumping into a air .',\n 'a man in a white shirt and white pants is standing on a stage .',\n 'a woman in a black dress is holding a red and white dog .',\n 'a boy jumps off a ramp .',\n 'a man in a red shirt is standing on a bench .',\n 'a man in a blue shirt is climbing a rock wall .',\n 'a boy is holding a baby in a chair .',\n 'a boy in a red shirt and a helmet is riding a skateboard down a ramp .',\n 'a boy jumps off a wooden fence .',\n 'a man and a woman are sitting on a beach .',\n 'a little girl in a pink dress is running on the beach .',\n 'a little girl in a pink dress is sitting on a tire swing .',\n 'a dog runs through the grass .',\n 'a child in a blue dress is holding a baby in a blue chair .',\n 'a woman in a red dress is holding a red and white dress .',\n 'a man in a white shirt is sitting on a bench .',\n 'a man in a blue shirt is sitting on a bench .',\n 'a group of people are standing in a field of a crowd .',\n 'a boy in a blue shirt is standing in a forest .',\n 'a girl in a pink bathing suit is walking through the water .',\n 'a little boy in a blue shirt is jumping over a fence .',\n 'a boy in a blue shirt is holding a baby in a blue shirt .',\n 'a boy in a blue shirt is holding a stick in his mouth .',\n 'a group of people are posing for a picture .',\n 'a man in a black shirt and a black shirt and a woman in a black shirt .',\n 'a man in a white shirt and a man in a white shirt and a man in a white',\n 'a man and a woman in a black shirt and a black shirt .',\n 'a girl in a black shirt is sitting on a couch .',\n 'a young boy with a baby in a chair .',\n 'a man is standing on a hill with a mountain in the background .',\n 'a boy in a blue shirt is jumping in the air .',\n 'a boy in a baseball uniform is running on the field .',\n 'a dog is running through a snowy hill .',\n 'a dog is running through the snow .',\n 'two children playing in the sand .',\n 'a man is climbing a rock wall .',\n 'a little boy in a blue shirt is holding a baby in a red shirt .',\n 'a man in a red shirt is riding a bike in the street .',\n 'a man in a red shirt is standing on a bench .',\n 'a man in a yellow jacket is skiing down a snowy hill .',\n 'a boy in a yellow shirt is holding a yellow toy .',\n 'a baby with a baby in a room .',\n 'a girl in a pink shirt is standing in a pool .',\n 'a man in a black shirt is jumping into a lake .',\n 'a boy in a blue shirt is running through a puddle .',\n 'a boy is jumping on a trampoline .',\n 'two girls are sitting on a trampoline .',\n 'a young boy in a bathing suit is jumping into a pool .',\n 'a boy in a yellow shirt is running through the grass .',\n 'three dogs are running through the snow .',\n 'a dog with a red collar is running through the snow .',\n 'a white dog runs through a forest .',\n 'a dog jumps over a tree branch in the woods .',\n 'a dog is running down a snowy hill .',\n 'a dog is jumping over a wooden fence .',\n 'a brown dog is running through a field .',\n 'a group of people stand in front of a large building .',\n 'a group of people in a white and white coat and a white dog in the snow .',\n 'a group of people stand in front of a tent .',\n 'a car is driving through a city street .',\n 'a large group of people are in the air .',\n 'a dog is running through the water .',\n 'a brown dog is laying on a wooden bench .',\n 'a white dog is running through a grassy area .',\n 'a man and a dog are running on a beach .',\n 'a black dog with a white dog in its mouth .',\n 'a young boy is holding a baby in his mouth .',\n 'a man in a blue wetsuit is riding a wave .',\n 'a brown dog is running on a dirt path .',\n 'a man is standing on a hill with a mountain in the background .',\n 'a man in a red shirt is riding a bike through a field .',\n 'a dog is running through the snow .',\n 'a dog with a pink collar is jumping in the air .',\n 'a man in a black jacket and a black jacket is standing on a sidewalk .',\n 'two dogs are running on the beach .',\n 'a man is climbing a rock .',\n 'a black dog is running through the snow .',\n 'two dogs are running through the snow .',\n 'a white dog is running through a snowy area .',\n 'two dogs are running through a field .',\n 'a black dog runs through the grass .',\n 'a young boy is holding a baby in a blue and white shirt .',\n 'a boy in a blue shirt and a blue shirt is holding a camera .',\n 'a brown dog running through the water .',\n 'a black and white dog is running through a field .',\n 'a man in a red jacket is sitting on a tent with a red tent .',\n 'a girl in a red jacket is skiing down a snowy hill .',\n 'a man is standing in the snow .',\n 'a skier is skiing down a snowy hill .',\n 'a man in a white shirt is standing in front of a white building .',\n 'a dog jumps in the air .',\n 'a man in a red shirt is doing a trick on a skateboard .',\n 'a boy jumps into the air on a trampoline .',\n 'a black dog is laying on the snow .',\n 'two dogs are running in the snow .',\n 'a man in a blue shirt is standing on a wall .',\n 'a man in a black jacket is riding a red and white dog .',\n 'a black dog is laying on a black dog .',\n 'a black dog running through the grass .',\n 'a man in a red shirt is standing in front of a store .',\n 'a man in a yellow shirt is riding a bike in a city .',\n 'a man in a black jacket is standing in front of a store .',\n 'a black dog is standing on a rock face .',\n 'a boy in a yellow shirt is standing on a colorful slide .',\n 'a group of people are walking on a sidewalk .',\n 'a dog jumps over a red frisbee .',\n 'a man is standing on a rocky cliff overlooking a rocky area .',\n 'a dog running on a beach .',\n 'a man in a blue shirt and a blue shirt is standing in front of a man with a',\n 'two people are standing on a sidewalk .',\n 'a woman in a white dress and a dog is walking on a sidewalk .',\n 'a man is sitting on a subway car .',\n 'a group of people are standing in front of a large crowd .',\n 'a black and white dog is playing with a ball in its mouth .',\n 'a man in a black jacket and a woman in a black jacket and a black jacket and a',\n 'a white dog jumps over a white frisbee .',\n 'a group of children in a colorful dress .',\n 'a group of people are playing a game .',\n 'a dog with a black collar is running on the floor .',\n 'a brown dog is running through the snow .',\n 'a black dog is running through the snow .',\n 'a man in a red jacket is walking through the snow .',\n 'a black dog is running through the grass .',\n 'a black and white dog running through a field .',\n 'a small dog is playing with a ball .',\n 'a man in a black shirt is sitting on a bus .',\n 'a man in a yellow shirt is standing on a wooden bench .',\n 'a dog is running through the snow .',\n 'a man in a black shirt is standing in front of a man in a black shirt .',\n 'a little boy in a white shirt is standing in a field with a white dog in a field',\n 'a man in a red jacket is standing in front of a large building .',\n 'a dog is running through the snow .',\n 'a man is riding a bike in the woods .',\n 'a man climbing a rock face .',\n 'a man in a red shirt is climbing a rock .',\n 'a man in a red shirt is climbing a rock face .',\n 'a man in a yellow jacket is walking down a street .',\n 'a man in a red shirt is standing on a sidewalk in front of a car .',\n 'a man in a blue jacket is standing on a snowy mountain .',\n 'a little boy in a red jacket is running through the snow .',\n 'a man in a red shirt climbs a rock .',\n 'a brown dog is running through a grassy field .',\n 'a man in a red jacket is standing on a mountain .',\n 'a man in a black shirt is standing in front of a man in a subway .',\n 'a man in a blue shirt and a backpack is standing on a rock .',\n 'a dog is running through the water .',\n 'a black and brown dog running through the grass .',\n 'a man in a blue shirt is sitting on a bench .',\n 'a man in a red shirt and a woman in a red shirt and a woman in a red',\n 'a man sitting on a bench .',\n 'a man in a white shirt is sitting on a bench in a chair .',\n 'a dog is running through the water .',\n 'a black and white dog is running through the snow .',\n 'a woman in a white shirt is standing on a stage .',\n 'a brown dog is jumping over a hurdle .',\n 'a dog running on the beach .',\n 'a brown and white dog is running through a grassy field .',\n 'a man and a dog are standing in the grass .',\n 'a young boy is holding a baby in a chair .',\n 'a man in a red shirt is standing in front of a red and white house .',\n 'a black dog is running through the snow .',\n 'a man in a blue wetsuit is surfing in the ocean .',\n 'a black dog is jumping in the snow .',\n 'a group of people are riding a dirt bike in the snow .',\n 'a boy in a blue shirt is holding a baby in a plastic plastic toy .',\n 'a dog is running through the snow .',\n 'a black dog is running through the snow .',\n 'a little girl in a pink shirt is sitting on a playground .',\n 'a man in a blue shirt climbs a rock face .',\n 'a white dog is running through a field .',\n 'a man in a black jacket is standing in front of a store .',\n 'a group of people are playing in a race .',\n 'a man in a red helmet and a helmet is riding a bike .',\n 'a man in a blue shirt climbs a rock face .',\n 'a white dog runs through the woods .',\n 'a girl in a pink shirt is holding a rope in a playground .',\n 'a dog is running through the snow .',\n 'a white dog is running through a lake .',\n 'a surfer is surfing a wave .',\n 'a black dog with a black collar is laying on a white carpet .',\n 'a dog is running on a dirt road .',\n 'a black dog is jumping into a pond .',\n 'a boy in a blue shirt is sitting on a bench .',\n 'a dog is running through the water .',\n 'a man and a child in a blue chair .',\n 'a man in a black shirt is standing on a bench with a man in a black shirt .',\n 'a man in a white shirt and a white shirt and a white dog .',\n 'a man in a black shirt and a black hat and a black hat .',\n 'two dogs are running through snow .',\n 'a dog runs through a field .',\n 'a brown dog is running on a green field .',\n 'a woman in a red jacket is walking down a snowy hill .',\n 'a man in a white shirt and a white shirt and a woman in a white shirt and a',\n 'a man in a black shirt and a black dog running in a field .',\n 'a dog jumps over a hurdle .',\n 'a dog jumps in the air .',\n 'two dogs are running in the grass .',\n 'a group of people dressed in colorful costumes and a woman in a green dress .',\n 'a boy in a blue shirt is running through a field .',\n 'a girl in a red jacket is walking through a tree .',\n 'a man in a white shirt and a white shirt and a black shirt and a white shirt and',\n 'a man in a red jacket and a black jacket and a woman in a red jacket .',\n 'a man in a white shirt is holding a baby in a crowd .',\n 'a dog is running through the snow .',\n 'a man is sitting on a dock near a lake .',\n 'a group of people are sitting on a bench .',\n 'a man in a blue shirt is walking on a sidewalk .',\n 'a black and white dog is running through the grass .',\n 'a boy in a black shirt is jumping over a white dog .',\n 'a man in a black jacket is walking on a sidewalk .',\n 'a man is standing on a skateboard in the air .',\n 'a young boy wearing a black shirt is sitting on a bench .',\n 'a brown dog is running through a field .',\n 'a brown and white dog with a red collar runs through the grass .',\n 'a woman in a red shirt is standing on a subway train .',\n 'a young girl in a blue shirt and a blue shirt is standing on a sidewalk .',\n 'a black dog is running through a field .',\n 'a woman in a red jacket is walking down a sidewalk .',\n 'a woman in a pink dress is standing in a colorful dress .',\n 'a man in a blue shirt and a white shirt and a black hat and a black hat and',\n 'a man in a black jacket is standing on a rock .',\n 'a dog runs through the woods .',\n 'a brown dog is running through a field .',\n 'a dog is running through the water .',\n 'a man in a blue shirt rides a bike in the air .',\n 'a young girl in a blue shirt is jumping into a pool .',\n 'a dog jumps over a hurdle .',\n 'a dog is running through the water .',\n 'a man in a blue shirt and a black hat and a woman walking down a street .',\n 'a brown dog is running through the grass .',\n 'a brown and white dog is running through a grassy field .',\n 'a dog runs through the grass .',\n 'a person in a blue jacket is standing in the snow .',\n 'a man in a black jacket and a brown dog is running through a field .',\n 'a boy in a yellow shirt is jumping over a ramp .',\n 'a person in a red shirt is standing on a red and red car .',\n 'a man in a black shirt and a woman in a black jacket .',\n 'a little girl in a pink shirt is running through a grassy field .',\n 'a black dog is running through a field .',\n 'a man in a green shirt is walking down a street .',\n 'a man in a green shirt is standing on a sidewalk .',\n 'a dog is jumping over a hurdle .',\n 'a man is standing on a red bench .',\n 'a brown dog is running through a forest .',\n 'two people are standing in front of a brick wall .',\n 'a man in a green shirt is standing in front of a store .',\n 'a man in a blue shirt is standing on a bench in front of a building .',\n 'a man in a red jacket is skiing down a snowy hill .',\n 'a boy in a blue shirt is sitting on a bench .',\n 'a little boy runs through the grass .',\n 'a man is standing on a beach .',\n 'a man is standing in the water at the beach .',\n 'three dogs are playing in a field .',\n 'a girl in a pink dress is sitting on a couch .',\n 'a dog is jumping in a yard .',\n 'a woman in a white dress and a woman in a pink dress and a white dress .',\n 'a group of people in a red and white shirt and a red shirt .',\n 'a man in a black shirt and black pants is standing on a rock .',\n 'two dogs run through the grass .',\n 'a man is standing on a dock with a sunset in the background .',\n 'a girl in a red shirt is standing in front of a fence .',\n 'a man wearing a black jacket and a hat is sitting on a bench .',\n 'a man in a black shirt and a black shirt and a black dog is jumping up to catch',\n 'a dog is laying in the snow .',\n 'a group of people are walking on the beach .',\n 'a white dog is running through a forest .',\n 'a dog is running through the water .',\n 'a white dog is running through the snow .',\n 'a man in a black jacket is standing on a mountain .',\n 'a little girl in a blue shirt is riding a yellow pole .',\n 'a man in a black shirt is walking on a sidewalk .',\n 'a man in a white shirt and a white shirt is walking through a park .',\n 'a man in a yellow jacket is climbing a rock .',\n 'a group of people are standing in front of a large group of people .',\n 'a group of people are standing in front of a large tree .',\n 'a man in a blue shirt is standing on a rocky mountain .',\n 'a black and brown dog is running through the snow .',\n 'a man in a black jacket and a woman in a blue jacket and a woman in a blue',\n 'a man in a white shirt and a black shirt is jumping over a rock .',\n 'a man in a black shirt and a woman in a black jacket and a backpack is standing in',\n 'a man in a red jacket is sitting on a bench .',\n 'two brown dogs are running on a dirt path .',\n 'a dog runs through the grass .',\n 'a dog jumps over a frisbee .',\n 'a group of people are standing on a sidewalk .',\n 'a dog is running through the snow .',\n 'a man and a woman in a white shirt and a brown dog are walking on a dirt path',\n 'a small child is playing with a toy in a chair .',\n 'a dog is running through a grassy field .',\n 'a dog is running through a field .',\n 'a man is standing on a skateboard .',\n 'a dog runs through the grass .',\n 'a little girl in a blue shirt is holding a playground .',\n 'a small dog is playing with a toy .',\n 'a man in a white shirt and a white shirt and a white dog walking on a beach .',\n 'a man and a woman are sitting on a rock .',\n 'a dog is jumping over a stream .',\n 'a dog jumps over a frisbee .',\n 'a dog is running through the sand .',\n 'a black dog runs through the grass .',\n 'a little boy is jumping over a wooden bench .',\n 'a baby is holding a baby in a chair .',\n 'a brown dog is running through the water .',\n 'a dog runs along a dirt road .',\n 'a man in a black shirt and a white shirt and a black shirt is walking down a street',\n 'a white dog is running on a grassy field .',\n 'a man in a black jacket is walking down a street .',\n 'a man is riding a huge wave in the snow .',\n 'a person in a yellow jacket is riding a bike .',\n 'a person in a blue shirt is standing on a ramp .',\n 'a brown dog is running through the grass .',\n 'a man in a blue shirt is standing on a rock .',\n 'two dogs are running through a field .',\n 'a girl in a pink shirt is jumping into the water .',\n 'a man is standing on a bench with a large brown and white dog .',\n 'a dog is jumping over a green toy .',\n 'a black and white dog jumps over a hurdle .',\n 'a brown dog is laying on a leash .',\n 'a group of people are walking down a road in the snow .',\n 'a man is jumping into the air on the beach .',\n 'a dog is running through the grass .',\n 'a man in a black shirt is jumping up a white dog .',\n 'a man in a black shirt and a black dog is standing on a trampoline .',\n 'a dog is running through the water .',\n 'a white dog is running through the air .',\n 'a dog is jumping over a white house .',\n 'a man in a white shirt and a woman in a white shirt and a woman in a white',\n 'a man is standing on a dock .',\n 'a man is climbing a rock face .',\n 'a man in a black jacket is standing next to a woman in a black jacket .',\n 'a black dog is jumping into the water .',\n 'a brown dog is laying on a brown dog .',\n 'a person is standing in a field .',\n 'a man in a red shirt is jumping over a tree .',\n 'a man in a blue shirt is standing on a street .',\n 'a dog is running through a grassy area .',\n 'a girl in a pink dress is jumping over a red object .',\n 'a black dog runs through a grassy field .',\n 'a dog with a red collar is running through the grass .',\n 'a woman in a white shirt is standing in front of a crowd of people .',\n 'a brown dog is running on a dirt path .',\n 'a dog runs through the grass .',\n 'a man in a red shirt is climbing a rock wall .',\n 'a man is climbing a rock wall .',\n 'a dog is running through the grass .',\n 'a dog is running on the beach .',\n 'a man in a black jacket is standing in front of a large rock .',\n 'a man is standing on a city street .',\n 'a group of people are walking through a field .',\n 'a dog with a yellow collar is in its mouth .',\n 'a dog is running through a wooden fence .',\n 'a black and white dog runs through the grass .',\n 'a young girl in a white dress is sitting on a bench .',\n 'a brown dog is swimming in water .',\n 'a man in a yellow shirt is standing on a rock .',\n 'a man is standing on a rock overlooking a forest .',\n 'a man in a black shirt is sitting on a table with a man in a blue shirt .',\n 'a man in a white shirt is standing on a bench with a white bag in the background .',\n 'a man in a blue shirt is standing on a rock overlooking a lake .',\n 'a man is standing in front of a large building .',\n 'a crowd of people in a city street .',\n 'a man in a black jacket is holding a sign .',\n 'a man in a blue shirt and a woman in a blue shirt and a red shirt and a',\n 'a girl in a red shirt is holding a baby in a blue shirt .',\n 'a man in a black jacket is standing on a hill .',\n 'a boy in a blue shirt is sitting on a bed .',\n 'a white dog with a white dog is running through the grass .',\n 'a little girl in a pink dress is holding a little girl in a pink dress .',\n 'a group of people are standing in front of a crowd .',\n 'two dogs are playing in the grass .',\n 'a group of people are standing in a field .',\n 'a black and white dog is running through the woods .',\n 'two dogs are playing in a grassy field .',\n 'two people are standing in front of a building .',\n 'a man and a woman are sitting on a bench .',\n 'a boy in a red shirt is standing on a rock wall .',\n 'two dogs are playing in the grass .',\n 'a white dog is running through the water .',\n 'a little girl in a pink shirt is walking on a beach .',\n 'a woman in a red shirt is walking on a sidewalk .',\n 'a man in a black shirt and a black shirt and a black shirt is standing on a sidewalk',\n 'a black dog running in a field .',\n 'a brown dog is running through the grass .',\n 'a boy is in a pool .',\n 'a white dog is running on a beach .',\n 'a man is climbing a rock face .',\n 'a man in a red jacket is standing on a snowy mountain .',\n 'a man in a red shirt and a woman in a white shirt and a woman walking down a',\n 'a man in a yellow shirt is doing a trick on a ramp .',\n 'two men are playing soccer .',\n 'two dogs are running through a field .',\n 'a man in a black helmet is riding a bike on a dirt bike .',\n 'a man in a red helmet is riding a bike .',\n 'a man in a red helmet is riding a bike in a field .',\n 'a man in a red helmet rides a bike on a dirt bike .',\n 'a man in a yellow hat and a woman in a white costume .',\n 'a man in a black shirt and a woman in a black shirt and a woman in a black',\n 'a man in a blue jacket is walking down a street .',\n 'a man in a city street .',\n 'a black and white dog is running through a grassy field .',\n 'a man and a woman sitting on a bench .',\n 'a brown dog is running through the water .',\n 'a group of people are sitting on a fire .',\n 'a group of people are sitting on a plastic car .',\n 'a man in a blue kayak is riding a wave .',\n 'a man in a yellow kayak is standing in the snow .',\n 'a woman in a black shirt is holding a baby in a store .',\n 'a woman in a blue shirt is sitting on a subway train .',\n 'two people are riding a raft in a raft in the water .',\n 'a group of people are in a boat in a river .',\n 'a black dog jumping over a tree .',\n 'a man in a white shirt and a woman in a white shirt and a woman in a white',\n 'a dog is running through the grass .',\n 'a man is jumping into a pool .',\n 'a little girl in a blue shirt is running on a field .',\n 'a white dog is running on a dirt road .',\n 'a man in a red jacket is skiing down a snowy hill .',\n 'a man is standing on a wooden bench .',\n 'a man in a red shirt and a black shirt and a black shirt and a black shirt and',\n 'two brown dogs are running through a field .',\n 'a boy in a swimming pool .',\n 'a black dog with a black dog is running through a grassy area .',\n 'a man in a yellow shirt is doing a trick on a ramp .',\n 'a black dog is running through the water .',\n 'a white dog is running through a red and white dog .',\n 'a dog with a red collar is running on the dirt road .',\n 'a person in a blue shirt is climbing a rock wall .',\n 'a group of people are riding a bike in a race .',\n 'a man in a black shirt and jeans is jumping on a trampoline .',\n 'a brown and white dog is running through the grass .',\n 'a dog is running on a leash .',\n 'a young boy in a blue shirt is standing on a bench with a blue sign .',\n 'a dog runs through the water .',\n ...]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load the model without long memory attention","metadata":{}},{"cell_type":"code","source":"#Bahdanau Attention\nclass Attention(nn.Module):\n    def __init__(self, encoder_dim,decoder_dim,attention_dim):\n        super(Attention, self).__init__()\n        \n        self.attention_dim = attention_dim\n        \n        self.decoder_attention = nn.Linear(decoder_dim,attention_dim)\n        self.encoder_attention = nn.Linear(encoder_dim,attention_dim)\n        \n        self.attention_layer = nn.Linear(attention_dim,1)\n        \n          \n        \n        \n    def forward(self, features, hidden_state):\n        encoder_attention_states = self.encoder_attention(features)     #(batch_size,num_layers,attention_dim)\n        decoder_attention_states = self.decoder_attention(hidden_state) #(batch_size,attention_dim)\n        \n        combined_states = torch.tanh(encoder_attention_states + decoder_attention_states.unsqueeze(1)) #(batch_size,num_layers,attemtion_dim)\n        \n        attention_scores = self.attention_layer(combined_states)         #(batch_size,num_layers,1)\n        attention_scores = attention_scores.squeeze(2)     #(batch_size,num_layers)\n        \n        \n        alpha = functional.softmax(attention_scores,dim=1)          #(batch_size,num_layers)\n        \n        attention_weights = features * alpha.unsqueeze(2)  #(batch_size,num_layers,features_dim)\n        attention_weights = attention_weights.sum(dim=1)   #(batch_size,num_layers)\n        \n        return alpha,attention_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:18:25.898201Z","iopub.execute_input":"2024-05-21T05:18:25.899385Z","iopub.status.idle":"2024-05-21T05:18:25.907698Z","shell.execute_reply.started":"2024-05-21T05:18:25.899341Z","shell.execute_reply":"2024-05-21T05:18:25.906772Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#Attention Decoder\nclass DecoderLSTM(nn.Module):\n    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,drop_prob=0.3):\n        super().__init__()\n        \n        #save the model param\n        self.vocab_size = vocab_size\n        self.attention_dim = attention_dim\n        self.decoder_dim = decoder_dim\n        \n        self.embedding = nn.Embedding(vocab_size,embed_size)\n        self.attention = Attention(encoder_dim,decoder_dim,attention_dim)\n        \n        self.init_h = nn.Linear(encoder_dim, decoder_dim)  \n        self.init_c = nn.Linear(encoder_dim, decoder_dim)  \n        self.lstm_cell = nn.LSTMCell(embed_size+encoder_dim,decoder_dim,bias=True)\n        \n        self.logits_layer = nn.Linear(decoder_dim,vocab_size)\n        self.drop = nn.Dropout(drop_prob)\n        \n        \n    \n    def forward(self, features, captions):\n        \n        #vectorize the caption\n        embeds = self.embedding(captions)\n        \n        # Initialize LSTM state\n        h, c = self.init_hidden_state(features)  # (batch_size, decoder_dim)\n        \n        #get the seq length to iterate\n        seq_length = len(captions[0])-1 #Exclude the last one\n        batch_size = captions.size(0)\n        num_features = features.size(1)\n        \n        preds = torch.zeros(batch_size, seq_length, self.vocab_size).to(device)\n        alphas = torch.zeros(batch_size, seq_length,num_features).to(device)\n                \n        for s in range(seq_length):\n            alpha,context = self.attention(features, h)\n            lstm_input = torch.cat((embeds[:, s], context), dim=1)\n            h, c = self.lstm_cell(lstm_input, (h, c))\n                    \n            output = self.logits_layer(self.drop(h))\n            \n            preds[:,s] = output\n            alphas[:,s] = alpha  \n        \n        \n        return preds, alphas\n    \n    def generate_caption(self, features, max_len=20, vocab=None):\n        # Inference part\n        # Given the image features generate the captions\n\n        batch_size = features.size(0)\n        h, c = self.init_hidden_state(features)  # (batch_size, decoder_dim)\n\n        alphas = []\n\n        # Starting input\n        word = torch.tensor(vocab.str_to_index['<SOS>']).view(1, -1).to(device)\n        embeds = self.embedding(word)\n\n        captions = []\n\n        for i in range(max_len):\n            alpha, context = self.attention(features, h)\n\n            # Store the alpha score\n            alphas.append(alpha.cpu().detach().numpy())\n\n            lstm_input = torch.cat((embeds[:, 0], context), dim=1)\n            h, c = self.lstm_cell(lstm_input, (h, c))\n            output = self.logits_layer(self.drop(h))\n            output = output.view(batch_size, -1)\n\n            # Replace <UNK> token with the most probable word\n            predicted_word_idx = output.argmax(dim=1)\n            if predicted_word_idx.item() == vocab.str_to_index['<UNK>']:\n                _, next_highest = torch.topk(output, 2, dim=1)\n                predicted_word_idx = next_highest[:, 1]  # Select the second most probable word\n            # Save the generated word\n            captions.append(predicted_word_idx.item())\n\n            # End if <EOS detected>\n            if vocab.index_to_str[predicted_word_idx.item()] == \"<EOS>\":\n                break\n\n            # Send the generated word as the next caption\n            embeds = self.embedding(predicted_word_idx.unsqueeze(0))\n\n        # Convert the vocab idx to words and return sentence\n        return [vocab.index_to_str[idx] for idx in captions], alphas\n    \n    \n    def init_hidden_state(self, encoder_out):\n        mean_encoder_out = encoder_out.mean(dim=1)\n        h = self.init_h(mean_encoder_out)  # (batch_size, decoder_dim)\n        c = self.init_c(mean_encoder_out)\n        return h, c","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:18:29.501705Z","iopub.execute_input":"2024-05-21T05:18:29.502151Z","iopub.status.idle":"2024-05-21T05:18:29.522311Z","shell.execute_reply.started":"2024-05-21T05:18:29.502108Z","shell.execute_reply":"2024-05-21T05:18:29.521436Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class EncoderDecoder(nn.Module):\n    def __init__(self,embed_size, vocab_size, attention_dim,encoder_dim,decoder_dim,image_transformation,drop_prob=0.3):\n        super().__init__()\n        self.embed_size=embed_size\n        self.vocab_size=vocab_size\n        self.attention_dim=attention_dim\n        self.encoder_dim=encoder_dim\n        self.decoder_dim=decoder_dim\n        \n        self.encoder = EncoderCNN()\n        self.decoder = DecoderLSTM(\n            embed_size=self.embed_size,\n            vocab_size = self.vocab_size,\n            attention_dim=self.attention_dim,\n            encoder_dim=self.encoder_dim,\n            decoder_dim=self.decoder_dim\n        )\n        self.image_transformation=image_transformation\n        \n    def forward(self, images, captions):\n        features = self.encoder(images)\n        outputs = self.decoder(features, captions)\n        return outputs\n    \n    #generate caption\n    def get_caps_from_image(self,image,show_image=False):\n        features_tensors = self.image_transformation(image).unsqueeze(0)\n        #generate the caption\n        model.eval()\n        with torch.no_grad():\n            features = self.encoder(features_tensors.to(device))\n            caps,alphas = self.decoder.generate_caption(features,vocab=train_dataset.vocab)\n            caption = ' '.join(caps)\n            if show_image:\n                show_image(features_tensors[0],title=caption)\n        return caption,caps,alphas\n        \n        \n    def save_model(self,num_epochs):\n        model_state = {\n            'num_epochs':num_epochs,\n            'embed_size':self.embed_size,\n            'vocab_size':self.vocab_size,\n            'attention_dim':self.attention_dim,\n            'encoder_dim':self.encoder_dim,\n            'decoder_dim':self.decoder_dim,\n            'image_transformation':self.image_transformation,\n            'state_dict':self.state_dict()\n        }\n\n        torch.save(model_state,f'attention_model_state_{num_epochs}.pth')\n    \n    @staticmethod\n    def load_model(path):\n        # Define the path to your saved model state dictionary\n        model_state_path = path\n\n        # Load the state dictionary\n        model_state = torch.load(model_state_path,map_location=torch.device('cpu'))\n\n        # Initialize your model architecture\n        model = EncoderDecoder(\n            embed_size=model_state['embed_size'],\n            vocab_size=model_state['vocab_size'],\n            attention_dim=model_state['attention_dim'],\n            encoder_dim=model_state['encoder_dim'],\n            decoder_dim=model_state['decoder_dim'],\n            image_transformation=model_state['image_transformation']\n        )\n\n        # Load the state dictionary into the model\n        model.load_state_dict(model_state['state_dict'])\n\n        # If the model was trained on GPU and you want to use it on GPU\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = model.to(device)\n\n        # Ensure the model is in evaluation mode\n        model.eval()\n        return model\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:18:40.285188Z","iopub.execute_input":"2024-05-21T05:18:40.285824Z","iopub.status.idle":"2024-05-21T05:18:40.300611Z","shell.execute_reply.started":"2024-05-21T05:18:40.285792Z","shell.execute_reply":"2024-05-21T05:18:40.299444Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Define the path to your saved model state dictionary\nmodel_state_path = \"/kaggle/input/short-term-attention/attention_model_state_200_short_memory.pth\"\nmodel=EncoderDecoder.load_model(model_state_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:18:52.830906Z","iopub.execute_input":"2024-05-21T05:18:52.831587Z","iopub.status.idle":"2024-05-21T05:18:55.136912Z","shell.execute_reply.started":"2024-05-21T05:18:52.831555Z","shell.execute_reply":"2024-05-21T05:18:55.136103Z"},"trusted":true},"execution_count":37,"outputs":[]}]}